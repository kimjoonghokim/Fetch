# Answer Confidence Scoring System

This directory contains a comprehensive scoring system for evaluating the confidence of answers generated by Large Language Models (LLMs).

## 📁 Files Overview

- **`scoring.py`** - Main scoring system with confidence calculation methods
- **`demo.py`** - Interactive demonstration and testing script (create this file if missing)

## 🎯 What is Confidence Scoring?

When an AI model generates text, it doesn't just pick one option - it considers many possible words/tokens and assigns probabilities to each. **Confidence scoring** uses these probabilities to determine how "sure" the model is about its answer.

Think of it like asking someone a math question:
- High confidence: "2+2=4" (very sure)
- Low confidence: "What's the 47th digit of pi? Um... maybe 3?" (uncertain)

## 🧮 Confidence Scoring Methods Explained

### 1. **Average Confidence** (Recommended)
- **What it is**: The average confidence across all tokens in the answer
- **Scale**: 0.0 to 1.0 (higher = more confident)
- **Use when**: You want a balanced overall confidence score
- **Example**: If the model generates "The answer is 4" with token confidences [0.9, 0.8, 0.7, 0.9], the average is 0.825

### 2. **Minimum Confidence** (Conservative)
- **What it is**: The confidence of the least confident token
- **Scale**: 0.0 to 1.0 (higher = more confident)
- **Use when**: You want to identify weak spots in the answer
- **Example**: Same answer as above, minimum confidence would be 0.7 (the weakest link)

### 3. **Geometric Confidence** (Multiplicative)
- **What it is**: Geometric mean of all token confidences
- **Scale**: 0.0 to 1.0 (higher = more confident)
- **Use when**: You want to penalize low-confidence tokens more heavily
- **Example**: More sensitive to outliers than average confidence

### 4. **Perplexity** (Technical)
- **What it is**: A measure of how "surprised" the model is by its own answer
- **Scale**: 1.0+ (lower = more confident)
- **Use when**: You're doing technical analysis or comparing across different text lengths
- **Example**: Perplexity of 1.2 (good) vs 5.8 (poor)

## 🚀 Quick Start

### Prerequisites
Make sure your vLLM policy server is running:
```bash
python3 -m vllm.entrypoints.openai.api_server \
  --model xmu-nlp/Llama-3-8b-gsm8k \
  --port 8000 \
  --dtype float16 \
  --tensor-parallel-size 2 \
  --swap-space 8 \
  --max-model-len 4096
```

### Run the Demo
```bash
cd /workspace/Fetch
python scorer/demo.py
```

This will show you:
- ✅ Basic confidence scoring examples
- 📊 Detailed scoring with all metrics
- 🪜 Step-by-step reasoning confidence
- 🔄 Comparison of different scoring methods

## 💻 Usage Examples

### Simple Confidence Check
```python
from scorer.scoring import get_simple_confidence

# Get a quick confidence score (0-1)
confidence = get_simple_confidence("What is 2+2?")
print(f"Confidence: {confidence:.3f}")
```

### Detailed Analysis
```python
from scorer.scoring import AnswerScorer

scorer = AnswerScorer()
result = scorer.get_confidence_score("What is 15*23?", "")

print(f"Answer: {result.text}")
print(f"Average Confidence: {result.avg_confidence:.3f}")
print(f"Minimum Confidence: {result.min_confidence:.3f}")
print(f"Perplexity: {result.perplexity:.2f}")
```

### Step-by-Step Reasoning
```python
# Evaluate confidence with previous context
question = "What is 25*16?"
context = "I need to multiply 25 by 16. Let me break this down:"

result = scorer.get_confidence_score(question, context)
print(f"With context confidence: {result.avg_confidence:.3f}")
```

### Different Scoring Methods
```python
from scorer.scoring import ScoringMethod

methods = [
    ScoringMethod.CONFIDENCE_AVERAGE,
    ScoringMethod.CONFIDENCE_MIN,
    ScoringMethod.PERPLEXITY
]

for method in methods:
    result = scorer.get_confidence_score("What is 7*9?", "", method=method)
    score = scorer.get_primary_score(result, method)
    print(f"{method.value}: {score:.3f}")
```

## 🔧 Configuration

You can customize the scoring system:

```python
from scorer.scoring import PolicyConfig, AnswerScorer

# Custom configuration
config = PolicyConfig(
    url="http://127.0.0.1",
    port=8000,
    model_name="your-model-name",
    temperature=0.5,
    max_tokens=256
)

scorer = AnswerScorer(config)
```

## 📊 Understanding Results

### Good Confidence Scores
- **Average confidence > 0.7**: Model is quite confident
- **Minimum confidence > 0.5**: No major weak spots
- **Perplexity < 2.0**: Model finds the answer predictable

### Poor Confidence Scores
- **Average confidence < 0.3**: Model is uncertain
- **Minimum confidence < 0.1**: Contains very uncertain tokens
- **Perplexity > 5.0**: Model finds the answer surprising/difficult

### Example Output
```
📝 Question: What is 12*15?
🤖 Generated Answer: 'The answer is 180.'
📈 Average Confidence: 0.756
⬇️  Minimum Confidence: 0.623
📐 Geometric Confidence: 0.742
🌀 Perplexity: 1.32

🔤 Token Details:
   'The' → 0.834
   ' answer' → 0.756
   ' is' → 0.623
   ' 180' → 0.812
   '.' → 0.891
```

This README provides:

1. **📁 Clear file overview** - What each file does
2. **🎯 Confidence scoring explanation** - What it is and why it matters  
3. **🧮 Method explanations** - Each scoring method explained in simple terms
4. **🚀 Quick start guide** - How to get running immediately
5. **💻 Usage examples** - Practical code examples
6. **📊 Results interpretation** - How to understand the output
7. **🔍 Troubleshooting** - Solutions to common problems
8. **🧪 Testing section** - How to verify everything works

The explanations assume no prior knowledge of confidence scoring while still being comprehensive enough for technical users!

## 🔍 Troubleshooting

### "Failed to parse" URL Error
**Problem**: URL shows as `http://127.0.0.1:8000:8000/v1/completions`
**Solution**: In `scoring.py`, line 38, change:
```python
# From:
url: str = "http://127.0.0.1:8000"
# To:
url: str = "http://127.0.0.1"
```

### "Cannot connect to server"
**Problem**: Demo shows connection error
**Solutions**:
1. Make sure vLLM server is running (see Prerequisites above)
2. Check if port 8000 is available
3. Verify the model name matches your server configuration

### "No confidence scores returned"
**Problem**: All confidence values are None or 0.0
**Solutions**:
1. Check that `logprobs=5` is being sent in the API request
2. Verify your vLLM server supports logprobs
3. Check server logs for errors

## 🔮 Future Features

The scoring system is designed to be extensible. Planned features include:

- **Parent/Child Node Quality**: Score based on reasoning tree structure
- **Semantic Similarity**: Compare answers to reference solutions
- **Ensemble Voting**: Combine multiple scoring methods
- **Custom Scoring Functions**: Add your own confidence metrics

## 🧪 Testing Your Setup

Quick test to verify everything works:

```bash
cd /workspace/Fetch
python3 -c "
from scorer.scoring import get_simple_confidence
try:
    score = get_simple_confidence('What is 1+1?')
    print(f'✅ Success! Confidence: {score:.3f}')
except Exception as e:
    print(f'❌ Error: {e}')
"
```

If you see a confidence score (like `0.756`), everything is working! 🎉

## 📚 Learn More

- **Log Probabilities**: The mathematical foundation of confidence scoring
- **Token-level Analysis**: Understanding word-by-word confidence
- **Perplexity**: A measure from information theory used in NLP
- **vLLM Documentation**: [https://docs.vllm.ai/](https://docs.vllm.ai/)

---

*Need help? Check the demo output or create an issue with your specific error message.*